\chapter{Related and Existing Work}
\label{chap:Related and Existing Work}

This chapter serves two purposes.
First we will discuss existing solutions and how our proposed implementation differentiates itself from them.
Then we will take a look at the academic side of file synchronization and discuss related papers.

\section{Existing Software}

For any interent technology two options exist how to structure its architecture, broadly speaking.
Most of the internet as it is today is cleanly divided in a client server structure where a client always request information from a central server.
This is a strongly hierarchical structure.
The opposite of this is a distributed, peer to peer model, where a client requests information from any other client and in turn will also respond to queries from other clients.
Both options have been used in existing file synchronization solutions.
Therefore we have divided the existing software we will shortly discuss in the following sections between these two extremes.

\subsection{Client Server Solutions}

For client server solutions any user must rely on the availability of the central server.
These are often hosted by third parties in a distributed manner for reasons of performance and scaling.

\subsubsection{Dropbox}

One of the most popular cloud storage providers currently, Dropbox~\cite{web:site:dropbox}, is known by many users looking for a solution that works across multiple operating systems.
Positive features include web access to stored data, clients for many different platforms, easy sharing of data with outsiders, and ease of use.
On the negative side the service relies on its back end servers, although computers can synchronize files between themselves on a local area network.
Dropbox also lacks any end to end encryption, but does encrypt data while in transit and when "at rest" in their data centers~\cite{web:site:dropbox:blog}.
Therefore it comes with little surprise that they were prominently featured in the Snowden leaks~\cite{web:site:rt:dropbox}.
The company does have full access to any data the user uploads to their servers, as long as they do not encrypt the files beforehand themselves.
This in turn means that they can offer up said data if required to by a government, as is the case in the United States of America.

Dropbox offers a free account for a basic storage plan.
Additional storage is available for purchase.
None of the core applications has been open sourced to date, meaning even if Dropbox implemented strong encryption it could not be independently verified.

\subsubsection{Google Drive}

Google Drive~\cite{web:site:gdrive} is similar to Dropbox from its functionality.
It does go a step further than Dropbox by integrating tightly with their suite of online applications for creating and editing documents, the so called Google Docs.
As can thus be quickly seen Google also has full access to all data that users upload to their servers.
This in turn means that under the PRISM program by the NSA, all such data is also retrievable by a fourth party~\cite{web:site:rt:google}.

Google also offers up a basic storage amount at no charge for the user.
Again additional space can be purchased on a monthly basis.
Apart from offering access via fewer clients than Dropbox, Google also has failed to open source the components of its service.

\subsubsection{Boxcryptor}

Both already mentioned services are thus not to be trusted with private information.
However solutions for encrypting the data sent over such services exist.
One example of such a service is the Boxcryptor software~\cite{web:site:boxcryptor}.
It encrypts all data before uploading it to the connected cloud storage service and decrypts it when retrieving it.
The user keys are attached to the user's account.
Asymmetric encryption is used to upload all keys to the companies key server so that other clients can retrieve and, with a correct password, decrypt the data.
Sharing of data is still possible even for users without an account by utilizing special keys.

The downside to this approach is mainly that it has to be used on top of an existing cloud storage service, although it works on most existing services.
However the software is again not open source and thus not independently verifiable.
Boxcryptor also offers a free version of its service, but to access all security features a paid subscription is required.

\subsection{Peer to Peer Solutions}

Peer to peer systems work without a central server.
The trade off is that such solutions require assistance in locating other peers, which means that some form of peer discovery must be implemented.
While this could be done via a central server, nowadays the common solution to the problem is a distributed hash table which is used to look up the required peers.
Once another peer has been found the connection can be established.
Apart form not relying on the availability and trustworthiness of a central server, peer to peer solutions offer up a possible performance advantage as they can distribute bandwidth between every peer, even actively unchoke an over saturated peer.
As an added bonus the path data takes between two peers will always be the most direct path as no data must first go towards a third party.

\subsubsection{BitTorrent Sync}
\label{subs:BitTorrent Sync}

An existing solution for a peer to peer data synchronization service is Sync~\cite{web:site:bittorrent_sync} from the BitTorrent company.
It is built on existing torrent technology and thus keeps many of the positive features associated with torrents: reducing the impact of transferring large files over a limited network.
Therefore it has no central point of failure and can even run without internet access by transferring files between computers on a local area network directly.
As the client server solutions before however Sync is closed source.
While information is encrypted in transfer, it can not be stored safely on third party machines without additional user involvement.

\subsubsection{Syncthing}
\label{subs:Syncthing}

Syncthing~\cite{web:site:synthing} is an open source file synchronization software on an equally free block exchange protocol.
This protocol is a mixed data transfer and communication protocol in one, with encryption for all communication built directly in.
Again however the user can not designate untrusted peers.

\section{Papers}
\label{sec:Papers}

The following discussion concerns papers that we believe have an impact on our work.
We discuss their broad content in no particular order, with a focus on what information we extracted and how we believe we can apply it to Tinzenite.

\subsection{What is a File Synchronizer?}
\label{sub:What is a File Synchronizer?}

This paper by Balasubramaniam and Pierce~\cite{balasubramaniam1998file} has the stated goal of offering up a framework for describing the behavior of file synchronizers.
Notably they divide the process into two separate phases: update detection and reconciliation.
Update detection is defined as the recognition of where updates have been made to the directory since the last synchronization.
Reconciliation is defined as the combination of updates between peers to transfer all peers to a new, synchronized state.

For Tinzenite we took a few things out of this paper: primarily the distinction between the update detection and the reconciliation phase.
We will also initially ignore links and file permissions due to increased complexity, but unlike them we will never modify a file ourself\footnote{TODO: state this as a goal somewhere, maybe relate it to the UNIX way of writing software: focus on what we came to do!}.
The paper also gave us a definition for the type of update detection strategy we wanted to try: namely the modtime inode strategy.
Ideally we would take an on-line update detector but this seems impossible to do under Linux currently.
Also of interest is the differentiation between pull and push models for propagating updates.
Tinzenite intends to be a hybrid between the two: while the main work will be done via push, once peers have established a connection updates may also be propagated via pull for performance reasons.
Of interest in the reconciliation section of the paper is the listing of the various possible states that two replicas of a directory can possibly reach given a set of operations.
We intend to ensure that the core protocol for Tinzenite will be capable of cleanly handling all of them.

\subsection{An Algebraic Approach to File Synchronization}
\label{sub:An Algebraic Approach to File Synchronization}

The paper by Ramsey and Csirmaz~\cite{ramsey2001algebraic} presents an algebra for reasoning about file system operations with the intended purpose of specifying an algorithm for file synchronization.
Interesting for our work is the discussion of possible commands that can be executed on said file algebra.
While from a user point of view a multitude of operations seems possible (create, remove, rename, move, derive, and edit) they distill these down to just three for the technical side: create, remove, and edit.
Rename can be executed by removing the original named file and creating a new file with the new name while keeping the contents identical.
Move can be executed much the same but keeps the name intact, instead changing the location where the new file is created.
Derive is argued to be indistinguishable from edit without higher level knowledge: while not impossible, beyond the scope for Tinzenite.

TODO: I think I can get more from this paper.
Note for example section 6 and the algebra.
Also take another look at the recon algo â€“ can I use it / parts of it?

\subsection{Peer-to-Peer Reconciliation Based Replication for Mobile Computers}
\label{sub:Peer-to-Peer Reconciliation Based Replication for Mobile Computers}

In~\cite{reiher1996peer}, Reiher et al. nicely state the benefits and drawbacks of using a peer to peer system for file synchronization in regard to mobile devices.
Benefits include not having to rely on an always on server, being able to transfer files without access to a central server, and transfering files over the shortest available network path.
The authors list as drawbacks the higher required complexity of the algorithms used to control the replication.
They conclude that peer to peer replication is well suited for mobile devices.

\subsection{Perspectives on Optimistically Replicated, Peer-to-Peer Filing}
\label{sub:Perspectives on Optimistically Replicated, Peer-to-Peer Filing}

The paper by Page et al.~\cite{page1998perspectives} is notable in our case for two main reasons.
It offers up a nice set of definitions of problems that we must also solve for Tinzenite and even offers up relevant solutions.
The authors also nicely discuss performance of their implementation.
Focus of the paper is the evaluation of the use of optimistic replica consistency, automatic update conflict detection and repair, the peer to peer interaction model, and the Ficus design and construction.

TODO: look at cites, might be able to use some of them too!

This paper discusses the insert delete ambiguity.
See page 6 for it.
"This resolves the insert/delete ambiguity at the cost of creating a garbage-collection problem: when is it safe to discard a logically deleted directory entry?"
And here is where I got stuck: "Successfully eliminating insert/delete ambiguities requires that prior to discarding a logically deleted directory entry, a directory replica must not only know that all replicas are marked deleted, but further must know that all other replicas are also aware of this fact."
And the following paragraph explains the solution: "
The garbage-collection algorithm proceeds in two phases.
Phase one compiles the list of replicas that know the entry is deleted.
Phase one ends and phase two begins at a replica when its list is complete, i.e., includes all replicas of the entry.
Phase two compiles the list of replicas that are known to have finished phase one, and concludes when this second list contains all replicas.
When phase two completes at a node, that node knows that all replicas know that all replicas have marked the entry deleted, and therefore it is safe to garbage collect the deleted entry.
Any other node that ever asks about the status of that entry will get the response "entry unknown" from which it can correctly conclude that garbage collection has finished at that site, and hence can finish at the inquirer as well.
There is no ambiguity since the inquirer knows, by virtue of being in phase two, that the other site once knew about the entry and its deletion.
Further discussion of these algorithms is available elsewhere.
"
TODO: look at that solution and see if I can use it (what happens when new peers are added while the algorithm is running? Can I do this for all deleted objects at once (ie for the list) instead of per object?).
ALSO: page 7 has thoughts on remove / update conflicts.
Basically they remove the DIR and move the orphaned file to a special dir\footnote{TODO: make this a hidden dir and also use for conflicts? The dir is handled normally by the sync apart from how files land in it. Clients can then work on conflicts everywhere and the solutions will be propagated correctly.}.
Also note the no updates lost policy!
FINALLY: also note the name conflicts part!

\section{Conclusion}
\label{sec:Conclusion}


TODO: list what we synthesized from all the related work here.

TODO: synthesize the feature I want from Tinzenite by going through a comparison of the already existing services (Bitsync, Syncthing, GDrive, Dropbox, etc).
Highlight what they do right and what they do wrong.
I'll expand on these features in the implementation chapter.

TODO: maybe also look at \url{http://www.symform.com/}.

TODO: These things need to be worked into architecture chapter:
Reconciliation: we'll keep conflicts and propagate as new files, leaving the user to manually sort it out.
Ideally, we'll offer assistance however (mark them in the dir?).
Insert/delete ambiguity!
I might be able to synthesize rules from this, for example: if a deletion conflicts, leave it be but mark (and apply updates within it if appropriate).

RUMOR --> sounds almost like mine, look at it!
What happens for my spec when a change results in the same content?
Theoretically nothing because version+1 and content hash is the same. :D

Note the following text where they discuss the implementation view of it!
RENAME replaced with MOVE, DERIVE can't be differentiated from EDIT, MOVE replaced with REMOVE and CREATE.
Having a lot of creates is good for my system because it resets version numbers!
